## Updates regarding Ultratimtrack

Changes

- Lines 274-288: add checking .mat file associated with mp4 file created from TvD2all to get automatic adjustment of the resolution mmPerPix and time axis
- Lines 329-333: similar to before, just creating the Time array according to the timestamps generated by Tvd2all as it has unconstant frame rate. 
- Lines 2402: change parfor library for the waitbar. Fix it for mac too

| Process   | Time (s)   | Notes                                     |
| --------- | ---------- | ----------------------------------------- |
| Parfor    | 454.132734 | Using 4 workers                           |
| Batch (1) | >1800      | Using 4 workers, and a job for each frame |
| Batch(2)  | 1713       | "Simple use "                               |

- Fixed flip image
- Fixed Clear
- Tried with reduced point features to track nearby the fascicle. No changes in tracking because it is local (hopefully)
- Should we add a box for adjusting via GUI the blocksize of opticflow? It seems to be the most critical parameter


## Tim mail

Just made a big change to the code, which I think is a big improvement. I uncoupled the aponeurosis and fascicle state estimation through adding a 3rd gain, fixing the bug with discussed. The key was making fascicle length a state in the state estimation.

For the fascicle, the 4 four states are now:

1. Superficial aponeurosis horizontal intersection point (corrected with a constant)
2. Superficial aponeurosis vertical intersection point (corrected with Hough or object detection on superficial aponeurosis)
3. Fascicle angle with the horizontal (corrected with Hough on fascicles)
4. Fascicle length (corrected with Hough or object detection on deep aponeurosis)

The 3 gains are:

1. Aponeurosis gain: corrects the Region of Interest (perhaps should be called ROI gain) --> **Then re-run OPTICFLOW** --> It's part of the drift according to TIM but I need to check
2. Fascicle – position gain: corrects the fascicle length according to ROI (perhaps should be called length gain) --> It's the most important
3. Fascicle – angle gain: corrects the fascicle angle according to Hough (independent of ROI/aponeurosis)

In general, gains 1 and 2 should depend on the quality of the aponeurosis-parts of the image, while gain 3 should depend on the quality of the fascicle-part of the image. Furthermore, because of non-linear relation between angle and length (i.e., cosine/sine), gain 3 should perhaps depend on the (average / minimal) fascicle angle (i.e., low gain if this angle is close to 0).

## To do

- [x] Auto cropping  --> fuck off
- [x] Manual cropping (add that it saves original images in case someone wants to reset)
- THERE IS AN ISSUE WITH CROPPING IN GENERAL...like the fascicle goes to the stars and the ROI moves
- [ ] Downsample image (by 2 maybe?) --> @Tim checks lines 2410 and 2467. I put a hint
	- [ ] Normal size: 145.267776 seconds (599 frames)
	- [ ] Half size:  72.574186 seconds --> just tim needs to check and correct the output because I don't know all of them, which needs to be x2 again
- [x] Block size 81 81 
- [x] Define a block size based on the muscle ROI.

In Lucas-Kanade and Tomasi's optical flow method, the block size refers to the size of the neighborhood around each pixel that is considered when estimating the motion. The block size plays a crucial role in the accuracy and sensitivity of the optical flow estimation.

Choosing a suitable block size depends on the characteristics of the images you are processing and the expected motion in the scene. Here are some guidelines to help you define a good block size:

1. **Spatial Resolution:** Consider the spatial resolution of your images. If your images have a high spatial resolution, you might be able to use a larger block size. Conversely, for lower-resolution images, a smaller block size may be more appropriate.

2. **Motion Scale:** Take into account the scale of the expected motion in your scene. If the motion is expected to be large, a larger block size may be suitable. Conversely, for small-scale motion, a smaller block size might be more accurate.

3. **Computational Cost:** Larger block sizes generally result in more computation because more pixels are involved in the estimation process. If computational efficiency is crucial, you might need to balance accuracy and speed by choosing a moderate block size.

4. **Image Content:** Consider the content of your images. If there are distinct features or structures in the scene, a larger block size may capture more information. However, if the scene is relatively uniform or lacks clear features, a smaller block size might be more appropriate.

5. **Noise Sensitivity:** Smaller block sizes tend to be more sensitive to noise, while larger block sizes may provide a more robust estimation by averaging over a larger area. If your images have significant noise, you may want to choose a block size that balances noise sensitivity and accuracy.

Ultimately, the choice of block size may require some experimentation and testing with your specific application and dataset. It's common to try different block sizes and evaluate their impact on the optical flow results to determine the most suitable size for your particular scenario.
- [x] Make parfor auto open in the begingging 
- [x] Make parfor to last as long as UTT is running and close it as soon as UTT is closed
- [x] Parallel branch and branch to the main branch
- [ ] TVD2All --> resolution issue?!!!!
- [x] Play around :D
- [x] Add that if someone change scale it recalculate fascicles length (line 2194)
- [x] Adjust waitbars name (edit function parfor_wait)
- [x] Adjust that clear fascicle callback, clean up the image, center it again and then make the axis again auto to adjust to the fascicle line extrapolated
- [x] Adjust the video play according to absolute values of fascicle extrap and image size (line 1922)

## Updates 21-03-2025 

- [x] Autodetect works only at frame 1-->handles.Region(i).Fascicle(j).fas_x{frame_no} must be initialized as empty
- [x] OR line2795 frame_no = 1 and geofeatuer at frame_no not necessary as it was a local variable for the selected frame
- [x] Changing resolution in the text box automatically adjust the fascicle length plot data
- [ ] opticflow is made to run only forward from frame n=1. While tim track is fine because each frame is independent, opticflow maybe be useful to go backwards as final fascicle length is the same so we have the opportunity to track the same one (rFE/rFD/REF) or also because the detected fascicle is not the best at frame 1 but maybe it is clear at frame 53 for example. 
- [x] When I use define fascicle, it looks like it plots outside (in the negative part or all x becomes negative)...basically the manually defined one is correct, the others tracked are shit. Maybe there is a fliplr issue?  --> it was the fucking fliplr
	-Just need to check whether it works for deeper compartment
- [ ] define tracking roi doesn't work
- [ ] if tim track fails, everything fails --> add a button or rather initialize the var so state_estimator use 0 / nan
- [x] **FIX WHY TIMTRACK WAS FAILING: line 2473 (not necessary to crop again the image, especially when autocrop works...it cut out part of the superficial aponeurosis and then tim track failed to catch the apo).** 
- [ ] Adjust tim track parm (2834???) should we keep it?  --> It seems you call the function "adjust_timtrack_parm", I just left it there...
- [x] When I apply the estimator, the beginning gets fucked (see images) --> maybe because of that ROI cut, it should be fixed now
- [ ] A message box that check tic toc of a single frame of timtrack and then chose to do the parfor or not based on the number of frames...
- [ ] Sensitivity analysis
- [ ] Tic toc a single frame for then time waitbar
- [x] Save timing of analysis (tim track, opticflow, paralell 1 or 0 in the mat data)
- [x] Save gains (1 x 3)
- [x] Save block size (1 x 2)
- [ ] Save resize value (to implement because Tim knows which values should be resized after the analysis, theoretically col 2 of coefs)
- [ ] Cut frames (before or after) works, but for plotting fascicle data purpose is then shifted...

- There are many Image 3d matrixes containing the images but I am not sure all of them are really necessary. As they can be big variables, they influenced the memory used. 
